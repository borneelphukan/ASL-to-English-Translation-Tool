# Sign-Language-Translation-Tool
Out of the entire 7.7 billion people of the world as of April 2019, it is estimated that 466 million people in the world are deprived of the ability to hear. It has been found that people who are deaf are also prone to being mute throughout their lives, although there are certain exceptions. Deaf people often can lip read but in order to communicate they do it through Sign Languages. Hand Gesture dependent Sign Language is a special type of conversation tool that is well understood by the deaf community but it is not well known amongst the general audience. This creates a huge communication gap between the general people and the deaf community all across the globe. This is the same reason why any deaf individual is treated differently than a normal able-bodied individual. So in order to break this stereotype, it is high time we create software which enables the proper translation of the Sign Language so that it can be understood by the people with no such disability. This project demonstrates one such technology made using Deep Convolutional Neural Network and Gesture Recognition.

## Steps to run the program

   **Step 1:** clone the repository using git clone "git address".
   
   **Step 2:** Install the packages using pip install -r requirements.txt.
   
   **Step 3:** Train the model using the command: _python model.py_.
   
   **Step 4:** Run the application using the command: _python camera.py_.
        
**Note: Training time is approximately 1-2 hour. I've trained it on Intel i7 9th Generation processor, 16GB RAM.**
